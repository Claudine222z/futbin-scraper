#!/usr/bin/env python3
"""
Futbin Mass Scraper - Coleta TODAS as cartas com m√°xima seguran√ßa
"""

import requests
import json
import time
import random
import re
import logging
import mysql.connector
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, asdict
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from tenacity import retry, stop_after_attempt, wait_exponential
import os
from telegram_bot import TelegramNotifier

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mass_scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class PlayerStats:
    velocidade: int
    finalizacao: int
    passe: int
    drible: int
    defesa: int
    fisico: int

@dataclass
class DetailedStats:
    # Velocidade
    aceleracao: int
    velocidade_sprint: int
    
    # Finaliza√ß√£o
    finalizacao_detalhada: int
    forca_chute: int
    chutes_longe: int
    voleios: int
    penaltis: int
    
    # Passe
    visao: int
    cruzamento: int
    precisao_livre: int
    passe_curto: int
    passe_longo: int
    curva: int
    
    # Drible
    agilidade: int
    equilibrio: int
    reacoes: int
    controle_bola: int
    drible_detalhado: int
    compostura: int
    
    # Defesa
    interceptacoes: int
    precisao_cabeca: int
    marcacao: int
    carrinho_em_pe: int
    carrinho_deslizante: int
    
    # F√≠sico
    salto: int
    resistencia: int
    forca: int
    agressao: int

@dataclass
class PlayerCard:
    id: str
    nome: str
    overall: int
    avaliacao: int
    posicao: str
    nacao: str
    liga: str
    clube: str
    pe_ruim: int
    habilidades: int
    altura: str
    peso: int
    pe_preferido: str
    data_nascimento: str
    accele_rate: str
    reputacao_internacional: int
    revisao: str
    atualizacao_preco: str
    escalao: str
    tipo_corpo: str
    id_clube: str
    id_liga: str
    posicoes_alternativas: List[str]
    estilos_jogo: List[str]
    estatisticas: PlayerStats
    estatisticas_detalhadas: DetailedStats
    precos: Dict[str, Dict[str, Any]]
    estilos_quimica: Dict[str, List[str]]
    posicoes: Dict[str, int]
    url_imagem: str
    url: str
    coletado_em: str
    funcoes: List[Dict[str, List[str]]]

class FutbinMassScraper:
    def __init__(self, telegram_token: str = None):
        self.base_url = "https://www.futbin.com"
        self.session = requests.Session()
        self.ua = UserAgent()
        
        # Usar vari√°veis de ambiente se n√£o fornecido
        if telegram_token is None:
            telegram_token = os.getenv('TELEGRAM_BOT_TOKEN', '8450381764:AAHS7rOLqUZjdoMgypzKaots282jf9CQlfw')
        
        self.telegram = TelegramNotifier(telegram_token)
        
        # Configura√ß√µes de seguran√ßa
        self.min_delay = 3.0
        self.max_delay = 7.0
        self.max_retries = 3
        self.notification_interval = 100
        
        # Estat√≠sticas
        self.stats = {
            'total_scraped': 0,
            'total_errors': 0,
            'start_time': None,
            'current_player': '',
            'success_count': 0,
            'error_count': 0
        }
        
        # Configurar headers aleat√≥rios
        self._update_headers()
    
    def _update_headers(self):
        """Atualiza headers com User-Agent aleat√≥rio"""
        self.session.headers.update({
            'User-Agent': self.ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
        })
    
    def _random_delay(self, min_delay: float = None, max_delay: float = None):
        """Delay aleat√≥rio entre requisi√ß√µes"""
        if min_delay is None:
            min_delay = self.min_delay
        if max_delay is None:
            max_delay = self.max_delay
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def _make_request(self, url: str) -> Optional[str]:
        """Faz requisi√ß√£o HTTP com retry e tratamento de erros"""
        try:
            self._random_delay()
            self._update_headers()
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            return response.text
                
        except Exception as e:
            logger.error(f"Erro ao fazer requisi√ß√£o para {url}: {e}")
            raise
    
    def get_all_player_urls(self) -> List[str]:
        """Obt√©m URLs de todos os jogadores do Futbin"""
        player_urls = []
        
        try:
            logger.info("üîç Obtendo lista de todos os jogadores...")
            
            # URL principal dos jogadores
            players_url = f"{self.base_url}/players"
            
            html = self._make_request(players_url)
            soup = BeautifulSoup(html, 'html.parser')
            
            # Procurar por links de jogadores
            player_links = soup.find_all('a', href=re.compile(r'/25/player/\d+'))
            
            for link in player_links:
                href = link.get('href')
                if href:
                    full_url = f"{self.base_url}{href}"
                    player_urls.append(full_url)
            
            # Se n√£o encontrou na primeira p√°gina, tentar pagina√ß√£o
            if len(player_urls) < 100:
                # Tentar diferentes p√°ginas
                for page in range(1, 11):  # Primeiras 10 p√°ginas
                    page_url = f"{players_url}?page={page}"
                    try:
                        html = self._make_request(page_url)
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        page_links = soup.find_all('a', href=re.compile(r'/25/player/\d+'))
                        for link in page_links:
                            href = link.get('href')
                            if href:
                                full_url = f"{self.base_url}{href}"
                                if full_url not in player_urls:
                                    player_urls.append(full_url)
                    except Exception as e:
                        logger.warning(f"Erro ao acessar p√°gina {page}: {e}")
                        continue
            
            logger.info(f"‚úÖ Encontrados {len(player_urls)} jogadores")
            return player_urls
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter URLs dos jogadores: {e}")
            return []
    
    def _extract_player_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """Extrai informa√ß√µes b√°sicas do jogador"""
        info = {}
        
        try:
            # Nome do jogador
            title_elem = soup.find('title')
            if title_elem:
                title_text = title_elem.get_text(strip=True)
                name_match = re.search(r'^([^-]+)', title_text)
                if name_match:
                    info['nome'] = name_match.group(1).strip()
            
            # Overall
            overall_elem = soup.find('div', class_='playercard-25-rating')
            if overall_elem:
                overall_text = overall_elem.get_text(strip=True)
                if overall_text.isdigit():
                    info['overall'] = int(overall_text)
            
            # Posi√ß√£o
            all_text = soup.get_text()
            position_patterns = [
                r'(\d{2})\s*(LW|RW|ST|CAM|CM|CDM|CB|LB|RB|GK)\s*\+\+',
                r'(\d{2})\s*(LW|RW|ST|CAM|CM|CDM|CB|LB|RB|GK)',
                r'(LW|RW|ST|CAM|CM|CDM|CB|LB|RB|GK)\s*\+\+',
                r'\b(LW|RW|ST|CAM|CM|CDM|CB|LB|RB|GK)\b'
            ]
            
            for pattern in position_patterns:
                position_match = re.search(pattern, all_text, re.IGNORECASE)
                if position_match:
                    if len(position_match.groups()) > 1:
                        position = position_match.group(2)
                    else:
                        position = position_match.group(1)
                    
                    if position and position.upper() in ['LW', 'RW', 'ST', 'CAM', 'CM', 'CDM', 'CB', 'LB', 'RB', 'GK']:
                        info['posicao'] = position.upper()
                        break
            
            # Na√ß√£o, Liga, Clube
            nation_patterns = ['Portugal', 'Brazil', 'Argentina', 'France', 'Germany', 'Spain', 'Italy', 'England']
            for pattern in nation_patterns:
                if pattern in all_text:
                    info['nacao'] = pattern
                    break
            
            league_patterns = ['Icons', 'Premier League', 'La Liga', 'Serie A', 'Bundesliga', 'Ligue 1']
            for pattern in league_patterns:
                if pattern in all_text:
                    info['liga'] = pattern
                    break
            
            club_patterns = ['EA FC ICONS', 'Manchester United', 'Real Madrid', 'Barcelona', 'Bayern Munich']
            for pattern in club_patterns:
                if pattern in all_text:
                    info['clube'] = pattern
                    break
            
        except Exception as e:
            logger.error(f"Erro ao extrair informa√ß√µes b√°sicas: {e}")
        
        return info
    
    def _extract_detailed_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """Extrai informa√ß√µes detalhadas do jogador - USANDO L√ìGICA DO SIMPLE_SCRAPER"""
        info = {}
        
        try:
            all_text = soup.get_text()
            
            # Skills
            skills_match = re.search(r'Skills\s*(\d+)', all_text, re.IGNORECASE)
            if skills_match:
                info['habilidades'] = int(skills_match.group(1))
            
            # Weak Foot
            weak_foot_match = re.search(r'Weak Foot\s*(\d+)', all_text, re.IGNORECASE)
            if weak_foot_match:
                info['pe_ruim'] = int(weak_foot_match.group(1))
            
            # International Reputation
            intl_rep_match = re.search(r'Intl\. Rep\s*(\d+)', all_text, re.IGNORECASE)
            if intl_rep_match:
                info['reputacao_internacional'] = int(intl_rep_match.group(1))
            
            # Foot
            foot_match = re.search(r'Foot\s*(Right|Left)', all_text, re.IGNORECASE)
            if foot_match:
                info['pe_preferido'] = foot_match.group(1)
            
            # Height
            height_match = re.search(r'Height\s*(\d+cm\s*\|\s*\d+\'?\d*")', all_text, re.IGNORECASE)
            if height_match:
                info['altura'] = height_match.group(1)
            
            # Weight
            weight_match = re.search(r'Weight\s*(\d+)', all_text, re.IGNORECASE)
            if weight_match:
                info['peso'] = int(weight_match.group(1))
            
            # Birthdate
            birthdate_match = re.search(r'Birthdate\s*(\d{2}-\d{2}-\d{4})', all_text, re.IGNORECASE)
            if birthdate_match:
                info['data_nascimento'] = birthdate_match.group(1)
            
            # AcceleRATE
            accele_match = re.search(r'AcceleRATE\s*([A-Za-z\s]+?)(?:\n|$)', all_text, re.IGNORECASE)
            if accele_match:
                accele_rate = accele_match.group(1).strip()
                if accele_rate and not any(keyword in accele_rate.lower() for keyword in ['club', 'nation', 'league', 'skills']):
                    info['accele_rate'] = accele_rate
            
            # Revision
            revision_match = re.search(r'Revision\s*([A-Za-z\s]+?)(?:\n|$)', all_text, re.IGNORECASE)
            if revision_match:
                revision = revision_match.group(1).strip()
                if revision and not any(keyword in revision.lower() for keyword in ['price', 'update']):
                    info['revision'] = revision
            
            # Price Update
            price_update_match = re.search(r'Price Update\s*([A-Za-z\s\d]+ago)', all_text, re.IGNORECASE)
            if price_update_match:
                info['atualizacao_preco'] = price_update_match.group(1).strip()
            
            # Squad
            squad_match = re.search(r'Squad\s*([A-Za-z0-9]+)', all_text, re.IGNORECASE)
            if squad_match:
                info['escalao'] = squad_match.group(1).strip()
            
            # Body Type
            body_type_match = re.search(r'B\.Type\s*([A-Za-z\s&]+?)(?:\n|$)', all_text, re.IGNORECASE)
            if body_type_match:
                body_type = body_type_match.group(1).strip()
                if body_type and not any(keyword in body_type.lower() for keyword in ['birthdate']):
                    info['tipo_corpo'] = body_type
            
            # ID
            id_match = re.search(r'ID\s*(\d+)', all_text, re.IGNORECASE)
            if id_match:
                info['id'] = id_match.group(1)
            
            # Club ID
            club_id_match = re.search(r'Club ID\s*(\d+)', all_text, re.IGNORECASE)
            if club_id_match:
                info['id_clube'] = club_id_match.group(1)
            
            # League ID
            league_id_match = re.search(r'League ID\s*(\d+)', all_text, re.IGNORECASE)
            if league_id_match:
                info['id_liga'] = league_id_match.group(1)
            
            # Alt POS (Posi√ß√µes alternativas) - L√ìGICA DO SIMPLE_SCRAPER
            alt_pos_patterns = [
                r'Alt POS\s*([A-Z,\s]+)',
                r'Alt POS\s*([A-Z]+(?:\s*\+\+)?(?:\s*,\s*[A-Z]+(?:\s*\+\+)?)*)',
                r'LM,\s*CAM,\s*RW',
                r'RW\s*\+\+\s*RM\s*\+\+\s*CAM\s*\+\+\s*R'
            ]
            
            for pattern in alt_pos_patterns:
                alt_pos_match = re.search(pattern, all_text, re.IGNORECASE)
                if alt_pos_match:
                    alt_positions_text = alt_pos_match.group(1).strip()
                    # Limpar e separar posi√ß√µes
                    alt_positions = []
                    for pos in alt_positions_text.split(','):
                        pos_clean = pos.strip()
                        # Remover texto extra ap√≥s quebras de linha
                        pos_clean = pos_clean.split('\n')[0].strip()
                        if pos_clean and pos_clean not in ['Alt POS', 'alt pos'] and len(pos_clean) <= 10:
                            alt_positions.append(pos_clean)
                    
                    if alt_positions:
                        info['posicoes_alternativas'] = alt_positions
                        break
            
            # Tentar extrair informa√ß√µes de na√ß√£o, liga e clube se n√£o foram encontradas antes
            if 'nacao' not in info:
                # Procurar por na√ß√µes espec√≠ficas
                nation_patterns = ['Portugal', 'Brazil', 'Argentina', 'France', 'Germany', 'Spain', 'Italy', 'England']
                for pattern in nation_patterns:
                    if pattern in all_text:
                        info['nacao'] = pattern
                        break
            
            if 'liga' not in info:
                # Procurar por ligas espec√≠ficas
                league_patterns = ['Icons', 'Premier League', 'La Liga', 'Serie A', 'Bundesliga', 'Ligue 1']
                for pattern in league_patterns:
                    if pattern in all_text:
                        info['liga'] = pattern
                        break
            
            if 'clube' not in info:
                # Procurar por clubes espec√≠ficos
                club_patterns = ['EA FC ICONS', 'Manchester United', 'Real Madrid', 'Barcelona', 'Bayern Munich']
                for pattern in club_patterns:
                    if pattern in all_text:
                        info['clube'] = pattern
                        break
        
        except Exception as e:
            logger.error(f"Erro ao extrair informa√ß√µes detalhadas: {e}")
        
        return info
    
    def _extract_detailed_stats(self, soup: BeautifulSoup) -> DetailedStats:
        """Extrai estat√≠sticas detalhadas do jogador"""
        stats = {
            'aceleracao': 0, 'velocidade_sprint': 0,
            'finalizacao_detalhada': 0, 'forca_chute': 0, 'chutes_longe': 0, 'voleios': 0, 'penaltis': 0,
            'visao': 0, 'cruzamento': 0, 'precisao_livre': 0, 'passe_curto': 0, 'passe_longo': 0, 'curva': 0,
            'agilidade': 0, 'equilibrio': 0, 'reacoes': 0, 'controle_bola': 0, 'drible_detalhado': 0, 'compostura': 0,
            'interceptacoes': 0, 'precisao_cabeca': 0, 'marcacao': 0, 'carrinho_em_pe': 0, 'carrinho_deslizante': 0,
            'salto': 0, 'resistencia': 0, 'forca': 0, 'agressao': 0
        }
        
        try:
            all_text = soup.get_text()
            
            stat_patterns = {
                'aceleracao': r'Acceleration\s*(\d+)',
                'velocidade_sprint': r'Sprint Speed\s*(\d+)',
                'finalizacao_detalhada': r'Finishing\s*(\d+)',
                'forca_chute': r'Shot Power\s*(\d+)',
                'chutes_longe': r'Long Shots\s*(\d+)',
                'voleios': r'Volleys\s*(\d+)',
                'penaltis': r'Penalties\s*(\d+)',
                'visao': r'Vision\s*(\d+)',
                'cruzamento': r'Crossing\s*(\d+)',
                'precisao_livre': r'FK Acc\.\s*(\d+)',
                'passe_curto': r'Short Pass\s*(\d+)',
                'passe_longo': r'Long Pass\s*(\d+)',
                'curva': r'Curve\s*(\d+)',
                'agilidade': r'Agility\s*(\d+)',
                'equilibrio': r'Balance\s*(\d+)',
                'reacoes': r'Reactions\s*(\d+)',
                'controle_bola': r'Ball Control\s*(\d+)',
                'drible_detalhado': r'Dribbling\s*(\d+)',
                'compostura': r'Composure\s*(\d+)',
                'interceptacoes': r'Interceptions\s*(\d+)',
                'precisao_cabeca': r'Heading Acc\.\s*(\d+)',
                'marcacao': r'Def\. Aware\s*(\d+)',
                'carrinho_em_pe': r'Stand Tackle\s*(\d+)',
                'carrinho_deslizante': r'Slide Tackle\s*(\d+)',
                'salto': r'Jumping\s*(\d+)',
                'resistencia': r'Stamina\s*(\d+)',
                'forca': r'Strength\s*(\d+)',
                'agressao': r'Aggression\s*(\d+)'
            }
            
            for stat_name, pattern in stat_patterns.items():
                match = re.search(pattern, all_text, re.IGNORECASE)
                if match:
                    stats[stat_name] = int(match.group(1))
        
        except Exception as e:
            logger.error(f"Erro ao extrair estat√≠sticas detalhadas: {e}")
        
        return DetailedStats(**stats)
    
    def _extract_playstyles(self, soup: BeautifulSoup) -> List[str]:
        """Extrai playstyles do jogador - L√ìGICA DO SIMPLE_SCRAPER"""
        playstyles = []
        
        try:
            # Playstyles espec√≠ficos baseados no simple_scraper
            expected_playstyles = [
                'Finesse Shot',
                'Technical',
                'Rapid',
                'Incisive Pass',
                'Low Driven Shot',
                'Chip Shot',
                'Power Shot',
                'Tiki Taka',
                'Quick Step',
                'Relentless',
                'Trivela',
                'Speed Dribbler',
                'Long Ball Pass',
                'Slide Tackle',
                'Power Header',
                'Acrobat',
                'Outside Foot Shot',
                'Flair',
                'Press Proven',
                'Intercept',
                'Block',
                'Giant Throw-in',
                'Set Piece Specialist',
                'One Club Player',
                'Leadership',
                'Second Wind',
                'Team Player',
                'Injury Free',
                'Solid Player'
            ]
            
            for playstyle in expected_playstyles:
                # Procurar por elementos que contenham este playstyle
                elements = soup.find_all(['div', 'span', 'p'], string=re.compile(playstyle, re.IGNORECASE))
                
                if elements:
                    # Verificar se √© playstyle plus (tem classe psplus no pai)
                    is_plus = False
                    for elem in elements:
                        parent = elem.parent
                        if parent and 'psplus' in parent.get('class', []):
                            is_plus = True
                            break
                    
                    # Adicionar playstyle com indica√ß√£o de plus se aplic√°vel
                    if is_plus:
                        playstyles.append(f"{playstyle} +")
                    else:
                        playstyles.append(playstyle)
            
        except Exception as e:
            logger.error(f"Erro ao extrair playstyles: {e}")
        
        return playstyles
    
    def _extract_prices(self, soup: BeautifulSoup) -> Dict[str, Dict[str, Any]]:
        """Extrai pre√ßos do jogador - L√ìGICA DO SIMPLE_SCRAPER"""
        prices = {}
        
        try:
            # Procurar por elementos de pre√ßo
            price_elements = soup.find_all(['div', 'span'], class_=re.compile(r'price|coin', re.IGNORECASE))
            
            for elem in price_elements:
                text = elem.get_text(strip=True)
                if text and any(char.isdigit() for char in text):
                    # Tentar extrair n√∫mero do pre√ßo
                    price_num = self._extract_price_number(text)
                    if price_num > 0:
                        # Determinar plataforma baseado no contexto
                        if 'ps' in elem.get('class', []) or 'playstation' in text.lower():
                            prices['psxbox'] = {'current': price_num, 'trend': 0, 'min': 0, 'max': 0}
                        elif 'xbox' in text.lower():
                            prices['xbox'] = {'current': price_num, 'trend': 0, 'min': 0, 'max': 0}
                        elif 'pc' in text.lower():
                            prices['pc'] = {'current': price_num, 'trend': 0, 'min': 0, 'max': 0}
                        else:
                            # Padr√£o
                            prices['psxbox'] = {'current': price_num, 'trend': 0, 'min': 0, 'max': 0}
        
        except Exception as e:
            logger.error(f"Erro ao extrair pre√ßos: {e}")
        
        return prices
    
    def _extract_price_number(self, text: str) -> int:
        """Extrai n√∫mero do pre√ßo de um texto"""
        try:
            # Remover caracteres n√£o num√©ricos exceto ponto e v√≠rgula
            clean_text = re.sub(r'[^\d.,]', '', text)
            
            # Converter para n√∫mero
            if clean_text:
                # Substituir v√≠rgula por ponto se necess√°rio
                clean_text = clean_text.replace(',', '.')
                return int(float(clean_text))
        except:
            pass
        
        return 0
    
    def _extract_chemistry_styles(self, soup: BeautifulSoup) -> Dict[str, List[str]]:
        """Extrai chemistry styles do jogador - L√ìGICA DO SIMPLE_SCRAPER"""
        chemistry_styles = {}
        
        try:
            # Lista de estilos de qu√≠mica conhecidos
            known_styles = [
                'Basic', 'Sniper', 'Finisher', 'Deadeye', 'Marksman', 'Hawk', 'Artist',
                'Architect', 'Powerhouse', 'Maestro', 'Engine', 'Sentinel', 'Guardian',
                'Gladiator', 'Backbone', 'Anchor', 'Hunter', 'Catalyst', 'Shadow'
            ]
            
            all_text = soup.get_text()
            
            # Procurar por estilos de qu√≠mica no texto
            for style in known_styles:
                if style in all_text:
                    chemistry_styles['general'] = chemistry_styles.get('general', []) + [style]
        
        except Exception as e:
            logger.error(f"Erro ao extrair estilos de qu√≠mica: {e}")
        
        return chemistry_styles
    
    def _extract_image_url(self, soup: BeautifulSoup) -> str:
        """Extrai URL da imagem do jogador - L√ìGICA DO SIMPLE_SCRAPER"""
        try:
            # Procurar especificamente pela imagem com a classe playercard-25-special-img
            player_card_img = soup.find('img', class_='playercard-25-special-img')
            if player_card_img:
                src = player_card_img.get('src', '')
                if src and 'futbin-green-small' not in src and 'logo' not in src.lower():
                    return src
            
            # Procurar por imagens do jogador
            # Procurar por elementos img com classes espec√≠ficas de jogador
            player_image_selectors = [
                'img[src*="players"]',
                'img[src*="player"]',
                '.player-image img',
                '.card-image img',
                '.player-card img',
                '.player-img img'
            ]
            
            for selector in player_image_selectors:
                img_elements = soup.select(selector)
                for img in img_elements:
                    src = img.get('src', '')
                    if src and 'futbin-green-small' not in src and 'logo' not in src.lower():
                        # Verificar se √© uma imagem de jogador
                        if any(keyword in src.lower() for keyword in ['player', 'card']):
                            return src
            
            # Procurar por elementos com classes espec√≠ficas
            player_containers = soup.find_all(['div', 'img'], class_=re.compile(r'player|card|image', re.IGNORECASE))
            
            for container in player_containers:
                if container.name == 'img':
                    src = container.get('src', '')
                    if src and 'futbin-green-small' not in src and 'logo' not in src.lower():
                        if any(keyword in src.lower() for keyword in ['player', 'card']):
                            return src
                else:
                    # Se √© um container, procurar por img dentro dele
                    img = container.find('img')
                    if img:
                        src = img.get('src', '')
                        if src and 'futbin-green-small' not in src and 'logo' not in src.lower():
                            if any(keyword in src.lower() for keyword in ['player', 'card']):
                                return src
            
            # Procurar por padr√µes espec√≠ficos de URL de imagem de jogador
            all_text = soup.get_text()
            img_patterns = [
                r'https://[^"\s]+players[^"\s]+\.(?:jpg|jpeg|png|webp)',
                r'https://[^"\s]+player[^"\s]+\.(?:jpg|jpeg|png|webp)'
            ]
            
            for pattern in img_patterns:
                matches = re.findall(pattern, str(soup), re.IGNORECASE)
                for match in matches:
                    if 'futbin-green-small' not in match and 'logo' not in match.lower():
                        return match
            
            # Se n√£o encontrou, retornar string vazia
            return ""
            
        except Exception as e:
            logger.error(f"Erro ao extrair URL da imagem: {e}")
            return ""
    
    def _extract_roles(self, soup: BeautifulSoup) -> List[Dict[str, List[str]]]:
        """Extrai roles do jogador - L√ìGICA DO SIMPLE_SCRAPER"""
        roles_info = []
        
        try:
            all_text = soup.get_text()
            lines = all_text.split('\n')
            
            # Procurar por se√ß√µes espec√≠ficas de roles
            # Baseado na an√°lise, as roles est√£o em se√ß√µes organizadas
            roles_sections = []
            
            # Procurar por se√ß√µes que come√ßam com posi√ß√µes
            valid_positions = ['LW', 'RW', 'LM', 'RM', 'CAM', 'CM', 'CDM', 'ST', 'CB', 'LB', 'RB', 'GK']
            
            # Mapear roles espec√≠ficas para cada posi√ß√£o baseado no exemplo fornecido
            expected_roles = {
                'LW': ['Winger', 'Inside Forward', 'Wide Playmaker'],
                'LM': ['Winger', 'Wide Midfielder', 'Wide Playmaker', 'Inside Forward'],
                'CAM': ['Playmaker', 'Shadow Striker', 'Half Winger', 'Classic 10'],
                'RW': ['Winger', 'Inside Forward', 'Wide Playmaker']
            }
            
            # Procurar por se√ß√µes de roles no texto
            for i, line in enumerate(lines):
                line = line.strip()
                
                # Verificar se √© uma posi√ß√£o v√°lida
                if line in valid_positions and line in expected_roles:
                    # Procurar por roles associadas a esta posi√ß√£o
                    position_roles = []
                    
                    # Procurar nas pr√≥ximas linhas por roles
                    for j in range(i+1, min(i+20, len(lines))):
                        next_line = lines[j].strip()
                        
                        # Se encontrar outra posi√ß√£o, parar
                        if next_line in valid_positions:
                            break
                        
                        # Verificar se √© uma role esperada para esta posi√ß√£o
                        for expected_role in expected_roles[line]:
                            if expected_role.lower() in next_line.lower():
                                # Verificar se tem ++ ou +
                                if '++' in next_line:
                                    position_roles.append(f"{expected_role} ++")
                                elif '+' in next_line:
                                    position_roles.append(f"{expected_role} +")
                                else:
                                    position_roles.append(f"{expected_role} ++")  # Padr√£o
                    
                    # Se encontrou roles para esta posi√ß√£o, adicionar
                    if position_roles:
                        roles_sections.append({
                            'position': line,
                            'roles': position_roles
                        })
            
            # Se n√£o encontrou se√ß√µes organizadas, usar m√©todo alternativo
            if not roles_sections:
                # Procurar por roles espec√≠ficas no texto
                for position, expected_role_list in expected_roles.items():
                    position_roles = []
                    
                    for role in expected_role_list:
                        # Procurar por padr√£o "role ++" ou "role +"
                        role_patterns = [
                            rf'{role}\s*\+\+',
                            rf'{role}\s*\+'
                        ]
                        
                        for pattern in role_patterns:
                            if re.search(pattern, all_text, re.IGNORECASE):
                                # Determinar o n√≠vel
                                if '++' in re.search(pattern, all_text, re.IGNORECASE).group():
                                    position_roles.append(f"{role} ++")
                                else:
                                    position_roles.append(f"{role} +")
                                break
                    
                    if position_roles:
                        roles_sections.append({
                            'position': position,
                            'roles': position_roles
                        })
            
            # Remover duplicatas e organizar
            unique_sections = {}
            for section in roles_sections:
                position = section['position']
                roles = section['roles']
                
                if position not in unique_sections:
                    unique_sections[position] = []
                
                # Adicionar apenas roles √∫nicas
                for role in roles:
                    if role not in unique_sections[position]:
                        unique_sections[position].append(role)
            
            # Converter de volta para lista
            final_roles_sections = []
            for position, roles in unique_sections.items():
                if roles:
                    final_roles_sections.append({
                        'position': position,
                        'roles': roles
                    })
            
            return final_roles_sections
            
        except Exception as e:
            logger.error(f"Erro ao extrair informa√ß√µes de roles: {e}")
        
        return roles_info
    
    def _extract_stats(self, detailed_stats: DetailedStats) -> PlayerStats:
        """Calcula estat√≠sticas principais"""
        return PlayerStats(
            velocidade=(detailed_stats.aceleracao + detailed_stats.velocidade_sprint) // 2,
            finalizacao=(detailed_stats.finalizacao_detalhada + detailed_stats.forca_chute + detailed_stats.chutes_longe + detailed_stats.voleios + detailed_stats.penaltis) // 5,
            passe=(detailed_stats.visao + detailed_stats.cruzamento + detailed_stats.precisao_livre + detailed_stats.passe_curto + detailed_stats.passe_longo + detailed_stats.curva) // 6,
            drible=(detailed_stats.agilidade + detailed_stats.equilibrio + detailed_stats.reacoes + detailed_stats.controle_bola + detailed_stats.drible_detalhado + detailed_stats.compostura) // 6,
            defesa=(detailed_stats.interceptacoes + detailed_stats.precisao_cabeca + detailed_stats.marcacao + detailed_stats.carrinho_em_pe + detailed_stats.carrinho_deslizante) // 5,
            fisico=(detailed_stats.salto + detailed_stats.resistencia + detailed_stats.forca + detailed_stats.agressao) // 4
        )
    
    def scrape_player(self, url: str) -> Optional[PlayerCard]:
        """Scrapa dados de um jogador espec√≠fico"""
        try:
            logger.info(f"Scrapando jogador: {url}")
            
            html = self._make_request(url)
            soup = BeautifulSoup(html, 'html.parser')
            
            # Extrair informa√ß√µes b√°sicas
            player_info = self._extract_player_info(soup)
            
            # Extrair informa√ß√µes detalhadas
            detailed_info = self._extract_detailed_info(soup)
            
            # Extrair estat√≠sticas detalhadas
            detailed_stats = self._extract_detailed_stats(soup)
            
            # Calcular estat√≠sticas principais
            stats = self._extract_stats(detailed_stats)
            
            # Extrair informa√ß√µes adicionais
            playstyles = self._extract_playstyles(soup)
            chemistry_styles = self._extract_chemistry_styles(soup)
            roles = self._extract_roles(soup)
            image_url = self._extract_image_url(soup)
            prices = self._extract_prices(soup)
            
            # Extrair ID do jogador da URL
            player_id = url.split('/')[-2] if url.endswith('/') else url.split('/')[-1]
            
            # Criar objeto PlayerCard
            player_card = PlayerCard(
                id=player_id,
                nome=player_info.get('nome', 'Desconhecido'),
                overall=player_info.get('overall', 0),
                avaliacao=player_info.get('overall', 0),
                posicao=player_info.get('posicao', 'Desconhecida'),
                nacao=player_info.get('nacao', 'Desconhecida'),
                liga=player_info.get('liga', 'Desconhecida'),
                clube=player_info.get('clube', 'Desconhecido'),
                pe_ruim=detailed_info.get('pe_ruim', 0),
                habilidades=detailed_info.get('habilidades', 0),
                altura=detailed_info.get('altura', ''),
                peso=detailed_info.get('peso', 0),
                pe_preferido=detailed_info.get('pe_preferido', ''),
                data_nascimento=detailed_info.get('data_nascimento', ''),
                accele_rate=detailed_info.get('accele_rate', ''),
                reputacao_internacional=detailed_info.get('reputacao_internacional', 0),
                revisao=detailed_info.get('revision', ''),
                atualizacao_preco=detailed_info.get('atualizacao_preco', ''),
                escalao=detailed_info.get('escalao', ''),
                tipo_corpo=detailed_info.get('tipo_corpo', ''),
                id_clube=detailed_info.get('id_clube', ''),
                id_liga=detailed_info.get('id_liga', ''),
                posicoes_alternativas=detailed_info.get('posicoes_alternativas', []),
                estilos_jogo=playstyles,
                estatisticas=stats,
                estatisticas_detalhadas=detailed_stats,
                precos=prices,
                estilos_quimica=chemistry_styles,
                posicoes={},
                url_imagem=image_url,
                url=url,
                coletado_em=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                funcoes=roles
            )
            
            logger.info(f"‚úÖ Jogador {player_info.get('nome', 'Desconhecido')} scrapado com sucesso")
            return player_card
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao scrapar jogador {url}: {e}")
            # Notificar erro via Telegram
            self.telegram.send_error_notification(str(e), url)
            return None
    
    def save_to_mysql(self, player: PlayerCard) -> bool:
        """Salva jogador no MySQL"""
        try:
            # Configura√ß√£o MySQL
            config = {
                'host': 'srv1577.hstgr.io',
                'user': 'u559058762_claudinez',
                'password': 'Cms332211',
                'database': 'u559058762_futbin'
            }
            
            connection = mysql.connector.connect(**config)
            cursor = connection.cursor()
            
            # SQL completo com todas as colunas da tabela players_horizontal
            insert_sql = """
            INSERT INTO players_horizontal (
                futbin_id, name, overall, rating, position, nation, league, club,
                weak_foot, skill_moves, international_reputation, foot, height, weight,
                body_type, birthdate, accele_rate, revision, price_update, squad,
                club_id, league_id, pace, shooting, passing, dribbling, defending, physical,
                acceleration, sprint_speed, finishing, shot_power, long_shots, volleys, penalties,
                vision, crossing, free_kick_accuracy, short_passing, long_passing, curve,
                agility, balance, reactions, ball_control, dribbling_detailed, composure,
                interceptions, heading_accuracy, marking, standing_tackle, sliding_tackle,
                jumping, stamina, strength, aggression, image_url, futbin_url,
                alt_positions_json, playstyles_json, prices_json, chemistry_styles_json, roles_json
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
            ) ON DUPLICATE KEY UPDATE
                name = VALUES(name),
                overall = VALUES(overall),
                pace = VALUES(pace),
                shooting = VALUES(shooting),
                passing = VALUES(passing),
                dribbling = VALUES(dribbling),
                defending = VALUES(defending),
                physical = VALUES(physical),
                acceleration = VALUES(acceleration),
                sprint_speed = VALUES(sprint_speed),
                finishing = VALUES(finishing),
                shot_power = VALUES(shot_power),
                long_shots = VALUES(long_shots),
                volleys = VALUES(volleys),
                penalties = VALUES(penalties),
                vision = VALUES(vision),
                crossing = VALUES(crossing),
                free_kick_accuracy = VALUES(free_kick_accuracy),
                short_passing = VALUES(short_passing),
                long_passing = VALUES(long_passing),
                curve = VALUES(curve),
                agility = VALUES(agility),
                balance = VALUES(balance),
                reactions = VALUES(reactions),
                ball_control = VALUES(ball_control),
                dribbling_detailed = VALUES(dribbling_detailed),
                composure = VALUES(composure),
                interceptions = VALUES(interceptions),
                heading_accuracy = VALUES(heading_accuracy),
                marking = VALUES(marking),
                standing_tackle = VALUES(standing_tackle),
                sliding_tackle = VALUES(sliding_tackle),
                jumping = VALUES(jumping),
                stamina = VALUES(stamina),
                strength = VALUES(strength),
                aggression = VALUES(aggression),
                updated_at = CURRENT_TIMESTAMP
            """
            
            # Valores completos (62 par√¢metros) para tabela players_horizontal
            values = (
                player.id, player.nome, player.overall, player.overall, player.posicao,
                player.nacao, player.liga, player.clube, player.pe_ruim, player.habilidades,
                player.reputacao_internacional, player.pe_preferido, player.altura, player.peso,
                player.tipo_corpo, player.data_nascimento, player.accele_rate, player.revisao,
                player.atualizacao_preco, player.escalao, player.id_clube, player.id_liga,
                player.estatisticas.velocidade, player.estatisticas.finalizacao, player.estatisticas.passe,
                player.estatisticas.drible, player.estatisticas.defesa, player.estatisticas.fisico,
                player.estatisticas_detalhadas.aceleracao, player.estatisticas_detalhadas.velocidade_sprint,
                player.estatisticas_detalhadas.finalizacao_detalhada, player.estatisticas_detalhadas.forca_chute,
                player.estatisticas_detalhadas.chutes_longe, player.estatisticas_detalhadas.voleios,
                player.estatisticas_detalhadas.penaltis, player.estatisticas_detalhadas.visao,
                player.estatisticas_detalhadas.cruzamento, player.estatisticas_detalhadas.precisao_livre,
                player.estatisticas_detalhadas.passe_curto, player.estatisticas_detalhadas.passe_longo,
                player.estatisticas_detalhadas.curva, player.estatisticas_detalhadas.agilidade,
                player.estatisticas_detalhadas.equilibrio, player.estatisticas_detalhadas.reacoes,
                player.estatisticas_detalhadas.controle_bola, player.estatisticas_detalhadas.drible_detalhado,
                player.estatisticas_detalhadas.compostura, player.estatisticas_detalhadas.interceptacoes,
                player.estatisticas_detalhadas.precisao_cabeca, player.estatisticas_detalhadas.marcacao,
                player.estatisticas_detalhadas.carrinho_em_pe, player.estatisticas_detalhadas.carrinho_deslizante,
                player.estatisticas_detalhadas.salto, player.estatisticas_detalhadas.resistencia,
                player.estatisticas_detalhadas.forca, player.estatisticas_detalhadas.agressao,
                player.url_imagem, player.url, json.dumps(player.posicoes_alternativas),
                json.dumps(player.estilos_jogo), json.dumps(player.precos),
                json.dumps(player.estilos_quimica), json.dumps(player.funcoes)
            )
            
            # Debug: contar valores (removido)
            
            cursor.execute(insert_sql, values)
            connection.commit()
            
            cursor.close()
            connection.close()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar no MySQL: {e}")
            return False
    
    def player_exists(self, player_id: str) -> bool:
        """Verifica se o jogador j√° existe no banco"""
        try:
            config = {
                'host': 'srv1577.hstgr.io',
                'user': 'u559058762_claudinez',
                'password': 'Cms332211',
                'database': 'u559058762_futbin'
            }
            
            connection = mysql.connector.connect(**config)
            cursor = connection.cursor()
            
            # Verificar se o jogador j√° existe
            check_sql = "SELECT COUNT(*) FROM players_horizontal WHERE futbin_id = %s"
            cursor.execute(check_sql, (player_id,))
            result = cursor.fetchone()
            
            cursor.close()
            connection.close()
            
            return result[0] > 0
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar se jogador existe: {e}")
            return False
    
    def _validate_player_data(self, player: PlayerCard) -> bool:
        """Valida se os dados do jogador est√£o completos"""
        try:
            # Verificar campos obrigat√≥rios
            required_fields = [
                player.nome, player.overall, player.posicao, 
                player.nacao, player.liga, player.clube
            ]
            
            if any(not field or field == 'Desconhecido' for field in required_fields):
                logger.warning(f"Dados b√°sicos incompletos para {player.nome}")
                return False
            
            # Verificar se as estat√≠sticas est√£o presentes
            if not player.estatisticas or not player.estatisticas_detalhadas:
                logger.warning(f"Estat√≠sticas ausentes para {player.nome}")
                return False
            
            # Verificar se a URL da imagem foi extra√≠da
            if not player.url_imagem:
                logger.warning(f"URL da imagem ausente para {player.nome}")
                return False
            
            # Verificar se roles foram extra√≠das (pode estar vazio, mas deve ser uma lista)
            if player.funcoes is None:
                logger.warning(f"Roles n√£o extra√≠das para {player.nome}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Erro ao validar dados do jogador {player.nome}: {e}")
            return False
    
    def _count_players_in_db(self) -> int:
        """Conta quantos jogadores existem no banco"""
        try:
            config = {
                'host': 'srv1577.hstgr.io',
                'user': 'u559058762_claudinez',
                'password': 'Cms332211',
                'database': 'u559058762_futbin'
            }
            
            connection = mysql.connector.connect(**config)
            cursor = connection.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM players_horizontal")
            count = cursor.fetchone()[0]
            
            cursor.close()
            connection.close()
            
            return count
            
        except Exception as e:
            logger.error(f"Erro ao contar jogadores no banco: {e}")
            return 0
    
    def _find_all_additional_players(self) -> List[str]:
        """Tenta encontrar TODOS os jogadores adicionais dispon√≠veis"""
        try:
            # Tentar acessar TODAS as p√°ginas do Futbin
            additional_urls = []
            
            # Buscar em muitas p√°ginas (at√© 50 p√°ginas)
            for page in range(2, 51):  # P√°ginas 2 a 50
                page_url = f"https://www.futbin.com/25/players?page={page}"
                
                try:
                    logger.info(f"üîç Verificando p√°gina {page}/50: {page_url}")
                    html = self._make_request(page_url)
                    
                    if html:
                        soup = BeautifulSoup(html, 'html.parser')
                        page_urls = self._extract_player_urls_from_page(soup)
                        
                        # Se n√£o encontrou nenhum jogador nesta p√°gina, parar
                        if not page_urls:
                            logger.info(f"üìÑ P√°gina {page} n√£o tem jogadores - parando busca")
                            break
                        
                        additional_urls.extend(page_urls)
                        logger.info(f"‚úÖ P√°gina {page}: {len(page_urls)} jogadores encontrados")
                    else:
                        logger.warning(f"‚ö†Ô∏è P√°gina {page} n√£o retornou HTML")
                        break
                    
                    self._random_delay(1.0, 2.0)
                    
                except Exception as e:
                    logger.error(f"Erro ao verificar p√°gina {page}: {e}")
                    continue
            
            logger.info(f"üéØ Total de jogadores adicionais encontrados: {len(additional_urls)}")
            return additional_urls
            
        except Exception as e:
            logger.error(f"Erro ao encontrar jogadores adicionais: {e}")
            return []
    
    def _find_additional_players(self) -> List[str]:
        """M√©todo legado - mantido para compatibilidade"""
        return self._find_all_additional_players()
    
    def _get_player_urls_from_page(self, page: int) -> List[str]:
        """Obt√©m URLs de jogadores de uma p√°gina espec√≠fica"""
        try:
            page_url = f"https://www.futbin.com/25/players?page={page}"
            logger.info(f"üîç Acessando p√°gina: {page_url}")
            
            html = self._make_request(page_url)
            if not html:
                logger.error(f"‚ùå P√°gina {page} n√£o retornou HTML")
                return []
            
            soup = BeautifulSoup(html, 'html.parser')
            return self._extract_player_urls_from_page(soup)
            
        except Exception as e:
            logger.error(f"Erro ao obter URLs da p√°gina {page}: {e}")
            return []
    
    def _extract_player_urls_from_page(self, soup: BeautifulSoup) -> List[str]:
        """Extrai URLs de jogadores de uma p√°gina espec√≠fica"""
        urls = []
        try:
            # Procurar por links de jogadores
            player_links = soup.find_all('a', href=re.compile(r'/25/player/\d+/'))
            
            for link in player_links:
                href = link.get('href')
                if href:
                    full_url = f"https://www.futbin.com{href}"
                    if full_url not in urls:
                        urls.append(full_url)
            
        except Exception as e:
            logger.error(f"Erro ao extrair URLs da p√°gina: {e}")
        
        return urls
    
    def _handle_section_completion(self, section_number: int, cards_per_section: int, pause_minutes: int):
        """Gerencia a conclus√£o de uma se√ß√£o"""
        try:
            logger.info(f"üéØ SE√á√ÉO {section_number} CONCLU√çDA!")
            logger.info(f"‚úÖ {cards_per_section} cartas coletadas nesta se√ß√£o")
            
            # Notificar via Telegram
            self.telegram.send_message(f"""
üéØ <b>SE√á√ÉO {section_number} CONCLU√çDA!</b>

‚úÖ <b>Cartas coletadas:</b> {cards_per_section}
üìä <b>Total at√© agora:</b> {self.stats['total_scraped']:,}
‚è∏Ô∏è <b>Pausa:</b> {pause_minutes} minutos

üîÑ <b>Status:</b> Pausando para evitar bloqueios...
            """)
            
            # Pausa entre se√ß√µes
            logger.info(f"‚è∏Ô∏è Pausando por {pause_minutes} minutos...")
            time.sleep(pause_minutes * 60)
            
            logger.info(f"üöÄ Retomando coleta - Pr√≥xima se√ß√£o...")
            
        except Exception as e:
            logger.error(f"Erro ao gerenciar conclus√£o da se√ß√£o: {e}")
    
    def _get_missing_fields(self, player: PlayerCard) -> List[str]:
        """Identifica campos faltantes no jogador"""
        missing_fields = []
        
        try:
            # Verificar campos obrigat√≥rios
            if not player.nome or player.nome == 'Desconhecido':
                missing_fields.append('nome')
            if not player.overall:
                missing_fields.append('overall')
            if not player.posicao or player.posicao == 'Desconhecido':
                missing_fields.append('posicao')
            if not player.nacao or player.nacao == 'Desconhecido':
                missing_fields.append('nacao')
            if not player.liga or player.liga == 'Desconhecido':
                missing_fields.append('liga')
            if not player.clube or player.clube == 'Desconhecido':
                missing_fields.append('clube')
            
            # Verificar estat√≠sticas
            if not player.estatisticas:
                missing_fields.append('estatisticas')
            if not player.estatisticas_detalhadas:
                missing_fields.append('estatisticas_detalhadas')
            
            # Verificar imagem
            if not player.url_imagem:
                missing_fields.append('url_imagem')
            
            # Verificar roles
            if player.funcoes is None:
                missing_fields.append('funcoes')
            
        except Exception as e:
            logger.error(f"Erro ao verificar campos faltantes: {e}")
        
        return missing_fields
    
    def _fix_incomplete_cards(self, incomplete_cards: List[Dict]):
        """Tenta corrigir cartas com dados incompletos"""
        try:
            logger.info(f"üîß Iniciando corre√ß√£o de {len(incomplete_cards)} cartas incompletas")
            
            fixed_count = 0
            
            for i, card_info in enumerate(incomplete_cards, 1):
                try:
                    logger.info(f"üîß Tentando corrigir carta {i}/{len(incomplete_cards)}: {card_info['name']}")
                    
                    # Tentar scrapar novamente
                    player = self.scrape_player(card_info['url'])
                    
                    if player and self._validate_player_data(player):
                        # Atualizar no banco
                        if self._update_player_in_db(player):
                            fixed_count += 1
                            self.stats['incomplete_count'] += 1
                            logger.info(f"‚úÖ Carta corrigida: {player.nome}")
                        else:
                            logger.error(f"‚ùå Erro ao atualizar carta: {player.nome}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Carta ainda incompleta: {card_info['name']}")
                    
                    # Delay entre tentativas
                    self._random_delay(5.0, 10.0)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro ao corrigir carta {card_info['name']}: {e}")
                    continue
            
            logger.info(f"üîß Corre√ß√£o conclu√≠da: {fixed_count}/{len(incomplete_cards)} cartas corrigidas")
            
        except Exception as e:
            logger.error(f"Erro ao corrigir cartas incompletas: {e}")
    
    def _update_player_in_db(self, player: PlayerCard) -> bool:
        """Atualiza um jogador existente no banco"""
        try:
            config = {
                'host': 'srv1577.hstgr.io',
                'user': 'u559058762_claudinez',
                'password': 'Cms332211',
                'database': 'u559058762_futbin'
            }
            
            connection = mysql.connector.connect(**config)
            cursor = connection.cursor()
            
            # SQL de atualiza√ß√£o
            update_sql = """
            UPDATE players_horizontal SET
                name = %s, overall = %s, position = %s, nation = %s, league = %s, club = %s,
                weak_foot = %s, skill_moves = %s, international_reputation = %s, foot = %s,
                height = %s, weight = %s, body_type = %s, birthdate = %s, accele_rate = %s,
                revision = %s, price_update = %s, squad = %s, club_id = %s, league_id = %s,
                pace = %s, shooting = %s, passing = %s, dribbling = %s, defending = %s, physical = %s,
                acceleration = %s, sprint_speed = %s, finishing = %s, shot_power = %s, long_shots = %s,
                volleys = %s, penalties = %s, vision = %s, crossing = %s, free_kick_accuracy = %s,
                short_passing = %s, long_passing = %s, curve = %s, agility = %s, balance = %s,
                reactions = %s, ball_control = %s, dribbling_detailed = %s, composure = %s,
                interceptions = %s, heading_accuracy = %s, marking = %s, standing_tackle = %s,
                sliding_tackle = %s, jumping = %s, stamina = %s, strength = %s, aggression = %s,
                image_url = %s, alt_positions_json = %s, playstyles_json = %s, prices_json = %s,
                chemistry_styles_json = %s, roles_json = %s, updated_at = CURRENT_TIMESTAMP
            WHERE futbin_id = %s
            """
            
            # Preparar valores
            values = (
                player.nome, player.overall, player.posicao, player.nacao, player.liga, player.clube,
                player.pe_ruim, player.habilidades, player.reputacao_internacional, player.pe_preferido,
                player.altura, player.peso, player.tipo_corpo, player.data_nascimento, player.accele_rate,
                player.revisao, player.atualizacao_preco, player.escalao, player.id_clube, player.id_liga,
                player.estatisticas.velocidade, player.estatisticas.finalizacao, player.estatisticas.passe,
                player.estatisticas.drible, player.estatisticas.defesa, player.estatisticas.fisico,
                player.estatisticas_detalhadas.aceleracao, player.estatisticas_detalhadas.velocidade_sprint,
                player.estatisticas_detalhadas.finalizacao_detalhada, player.estatisticas_detalhadas.forca_chute,
                player.estatisticas_detalhadas.chutes_longe, player.estatisticas_detalhadas.voleios,
                player.estatisticas_detalhadas.penaltis, player.estatisticas_detalhadas.visao,
                player.estatisticas_detalhadas.cruzamento, player.estatisticas_detalhadas.precisao_livre,
                player.estatisticas_detalhadas.passe_curto, player.estatisticas_detalhadas.passe_longo,
                player.estatisticas_detalhadas.curva, player.estatisticas_detalhadas.agilidade,
                player.estatisticas_detalhadas.equilibrio, player.estatisticas_detalhadas.reacoes,
                player.estatisticas_detalhadas.controle_bola, player.estatisticas_detalhadas.drible_detalhado,
                player.estatisticas_detalhadas.compostura, player.estatisticas_detalhadas.interceptacoes,
                player.estatisticas_detalhadas.precisao_cabeca, player.estatisticas_detalhadas.marcacao,
                player.estatisticas_detalhadas.carrinho_em_pe, player.estatisticas_detalhadas.carrinho_deslizante,
                player.estatisticas_detalhadas.salto, player.estatisticas_detalhadas.resistencia,
                player.estatisticas_detalhadas.forca, player.estatisticas_detalhadas.agressao,
                player.url_imagem, json.dumps(player.posicoes_alternativas), json.dumps(player.estilos_jogo),
                json.dumps(player.precos), json.dumps(player.estilos_quimica), json.dumps(player.funcoes),
                player.id
            )
            
            cursor.execute(update_sql, values)
            connection.commit()
            
            cursor.close()
            connection.close()
            
            return True
            
        except Exception as e:
            logger.error(f"Erro ao atualizar jogador no banco: {e}")
            return False
    
    def run_mass_scraping(self):
        """Executa o scraping em massa de TODAS as cartas - SISTEMA COMPLETO"""
        try:
            logger.info("üöÄ INICIANDO SCRAPING COMPLETO - TODAS AS 786 P√ÅGINAS")
            
            # Configura√ß√µes do sistema
            CARDS_PER_SECTION = 200  # Cartas por se√ß√£o
            PAUSE_MINUTES = 5  # Pausa entre se√ß√µes
            TOTAL_PAGES = 786  # Total de p√°ginas do Futbin
            CARDS_PER_PAGE = 30  # Cartas por p√°gina
            
            # Calcular total estimado
            total_estimated = TOTAL_PAGES * CARDS_PER_PAGE
            logger.info(f"üìä Total estimado: {total_estimated:,} cartas em {TOTAL_PAGES} p√°ginas")
            
            # Iniciar estat√≠sticas
            self.stats['start_time'] = datetime.now()
            self.stats['total_scraped'] = 0
            self.stats['success_count'] = 0
            self.stats['error_count'] = 0
            self.stats['skipped_count'] = 0
            self.stats['incomplete_count'] = 0
            self.stats['last_status_time'] = datetime.now()
            self.stats['last_summary_time'] = datetime.now()
            
            # Lista para cartas com dados incompletos
            incomplete_cards = []
            
            # Notificar in√≠cio via Telegram
            self.telegram.send_start_notification(total_estimated)
            
            # Conjunto para evitar URLs duplicadas
            processed_urls = set()
            current_section = 0
            
            # Coletar TODAS as p√°ginas
            for page in range(1, TOTAL_PAGES + 1):
                try:
                    logger.info(f"üìÑ Processando p√°gina {page}/{TOTAL_PAGES}")
                    
                    # Obter URLs da p√°gina atual
                    page_urls = self._get_player_urls_from_page(page)
                    
                    if not page_urls:
                        logger.warning(f"‚ö†Ô∏è P√°gina {page} n√£o retornou URLs")
                        continue
                    
                    logger.info(f"‚úÖ P√°gina {page}: {len(page_urls)} URLs encontradas")
                    
                    # Processar cada URL da p√°gina
                    for i, url in enumerate(page_urls, 1):
                        try:
                            # Verificar se j√° processamos esta URL
                            if url in processed_urls:
                                logger.info(f"‚è≠Ô∏è URL j√° processada: {url}")
                                self.stats['skipped_count'] += 1
                                continue
                            
                            processed_urls.add(url)
                            
                            # Extrair ID do jogador da URL
                            player_id = url.split('/')[-2] if url.endswith('/') else url.split('/')[-1]
                            
                            # Verificar se o jogador j√° existe no banco
                            if self.player_exists(player_id):
                                logger.info(f"‚è≠Ô∏è Jogador j√° existe no banco: {player_id}")
                                self.stats['skipped_count'] += 1
                                continue
                            
                            # Scrapar jogador
                            logger.info(f"üîç Scrapando: {url}")
                            player = self.scrape_player(url)
                            
                            if player:
                                # Validar se os dados est√£o completos
                                if self._validate_player_data(player):
                                    # Salvar no MySQL
                                    if self.save_to_mysql(player):
                                        self.stats['success_count'] += 1
                                        self.stats['total_scraped'] += 1
                                        logger.info(f"‚úÖ Jogador salvo: {player.nome}")
                                    else:
                                        self.stats['error_count'] += 1
                                        logger.error(f"‚ùå Erro ao salvar jogador: {player.nome}")
                                else:
                                    self.stats['incomplete_count'] += 1
                                    incomplete_cards.append({
                                        'url': url,
                                        'player_id': player_id,
                                        'name': player.nome,
                                        'missing_fields': self._get_missing_fields(player)
                                    })
                                    logger.warning(f"‚ö†Ô∏è Dados incompletos: {player.nome}")
                            else:
                                self.stats['error_count'] += 1
                            
                            # Verificar se chegou ao fim da se√ß√£o
                            if self.stats['total_scraped'] > 0 and self.stats['total_scraped'] % CARDS_PER_SECTION == 0:
                                current_section += 1
                                self._handle_section_completion(current_section, CARDS_PER_SECTION, PAUSE_MINUTES)
                            
                            # Verificar se deve enviar notifica√ß√£o de status (a cada 10 minutos)
                            current_time = datetime.now()
                            time_since_last_status = (current_time - self.stats['last_status_time']).total_seconds() / 60
                            
                            if time_since_last_status >= 10:  # 10 minutos
                                self.telegram.send_status_notification(
                                    self.stats['total_scraped'], 
                                    f"P√°gina {page}/{TOTAL_PAGES}",
                                    self.stats['success_count'],
                                    self.stats['error_count']
                                )
                                self.stats['last_status_time'] = current_time
                            
                            # Verificar se deve enviar resumo (a cada 20 minutos)
                            time_since_last_summary = (current_time - self.stats['last_summary_time']).total_seconds() / 60
                            
                            if time_since_last_summary >= 20:  # 20 minutos
                                self.telegram.send_summary_notification(
                                    self.stats['total_scraped'], 
                                    total_estimated,
                                    self.stats['success_count'],
                                    self.stats['error_count'],
                                    self.stats['skipped_count']
                                )
                                self.stats['last_summary_time'] = current_time
                            
                            # Delay entre jogadores
                            self._random_delay(3.0, 6.0)  # Delay maior para evitar bloqueios
                            
                        except Exception as e:
                            self.stats['error_count'] += 1
                            logger.error(f"‚ùå Erro ao processar jogador: {e}")
                            continue
                    
                    # Delay entre p√°ginas
                    self._random_delay(5.0, 10.0)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro ao processar p√°gina {page}: {e}")
                    continue
            
            # Processar cartas com dados incompletos
            if incomplete_cards:
                logger.info(f"üîÑ Processando {len(incomplete_cards)} cartas com dados incompletos")
                self._fix_incomplete_cards(incomplete_cards)
            
            # Verifica√ß√£o final
            final_count = self._count_players_in_db()
            logger.info(f"üìä Total final de jogadores no banco: {final_count}")
            
            # Calcular dura√ß√£o
            duration = datetime.now() - self.stats['start_time']
            duration_minutes = int(duration.total_seconds() / 60)
            
            # Notificar conclus√£o
            self.telegram.send_completion_notification(
                self.stats['success_count'],
                self.stats['error_count'],
                self.stats['skipped_count'],
                duration_minutes,
                final_count=final_count
            )
            
            logger.info(f"üéâ SCRAPING COMPLETO CONCLU√çDO!")
            logger.info(f"‚úÖ Sucessos: {self.stats['success_count']:,}")
            logger.info(f"‚ùå Erros: {self.stats['error_count']:,}")
            logger.info(f"‚è≠Ô∏è Pulados: {self.stats['skipped_count']:,}")
            logger.info(f"‚ö†Ô∏è Incompletos corrigidos: {self.stats['incomplete_count']:,}")
            logger.info(f"üìä Total no banco: {final_count}")
            logger.info(f"üéØ Meta: TODAS as cartas ({total_estimated:,})")
            logger.info(f"‚è±Ô∏è Dura√ß√£o: {duration_minutes} minutos")
            
            # Iniciar monitoramento cont√≠nuo
            logger.info("üîÑ INICIANDO MONITORAMENTO CONT√çNUO...")
            self.run_continuous_monitoring()
            
        except Exception as e:
            logger.error(f"‚ùå Erro fatal no scraping: {e}")
            self.telegram.send_error_notification(f"Erro fatal: {e}", "Sistema")

    def run_continuous_monitoring(self, check_interval_hours: int = 6):
        """Executa monitoramento cont√≠nuo para novas cartas"""
        try:
            logger.info(f"üîÑ INICIANDO MONITORAMENTO CONT√çNUO")
            logger.info(f"‚è∞ Verificando a cada {check_interval_hours} horas")
            
            self.telegram.send_monitoring_start(check_interval_hours)
            
            while True:
                try:
                    logger.info("üîç Verificando novas cartas...")
                    
                    # Contar cartas atuais no banco
                    current_count = self._count_players_in_db()
                    logger.info(f"üìä Cartas atuais no banco: {current_count}")
                    
                    # Verificar apenas as primeiras p√°ginas (onde novas cartas aparecem)
                    new_cards_found = 0
                    
                    for page in range(1, 11):  # Verifica apenas p√°ginas 1-10
                        try:
                            logger.info(f"üîç Verificando p√°gina {page}/10 para novas cartas")
                            
                            # Buscar URLs da p√°gina
                            page_urls = self._get_player_urls_from_page(page)
                            
                            for url in page_urls:
                                try:
                                    # Extrair ID do jogador
                                    player_id = url.split('/')[-2] if url.endswith('/') else url.split('/')[-1]
                                    
                                    # Verificar se √© uma carta nova
                                    if not self.player_exists(player_id):
                                        logger.info(f"üÜï Nova carta encontrada: {player_id}")
                                        
                                        # Scrapar com delay maior (modo lento)
                                        self._random_delay(10.0, 20.0)  # Delay maior no monitoramento
                                        
                                        player = self.scrape_player(url)
                                        
                                        if player and self._validate_player_data(player):
                                            if self.save_to_mysql(player):
                                                new_cards_found += 1
                                                logger.info(f"‚úÖ Nova carta salva: {player.nome}")
                                                
                                                # Notificar nova carta
                                                self.telegram.send_new_card_found(
                                                    player.nome, 
                                                    player.overall, 
                                                    player.posicao, 
                                                    player.clube, 
                                                    self._count_players_in_db()
                                                )
                                            else:
                                                logger.error(f"‚ùå Erro ao salvar nova carta: {player.nome}")
                                        else:
                                            logger.warning(f"‚ö†Ô∏è Nova carta com dados incompletos: {player_id}")
                                    
                                    # Delay entre verifica√ß√µes (modo lento)
                                    self._random_delay(5.0, 10.0)
                                    
                                except Exception as e:
                                    logger.error(f"‚ùå Erro ao verificar carta {url}: {e}")
                                    continue
                            
                            # Delay entre p√°ginas (modo lento)
                            self._random_delay(15.0, 30.0)
                            
                        except Exception as e:
                            logger.error(f"‚ùå Erro ao verificar p√°gina {page}: {e}")
                            continue
                    
                    # Relat√≥rio do ciclo
                    if new_cards_found > 0:
                        logger.info(f"üéâ CICLO COMPLETO: {new_cards_found} novas cartas encontradas!")
                    else:
                        logger.info("‚úÖ CICLO COMPLETO: Nenhuma nova carta encontrada")
                    
                    self.telegram.send_monitoring_cycle_complete(
                        new_cards_found, 
                        self._count_players_in_db(), 
                        check_interval_hours
                    )
                    
                    # Aguardar pr√≥ximo ciclo
                    logger.info(f"üò¥ Aguardando {check_interval_hours} horas para pr√≥xima verifica√ß√£o...")
                    time.sleep(check_interval_hours * 3600)  # Converter horas para segundos
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro no ciclo de monitoramento: {e}")
                    self.telegram.send_error_notification(f"Erro no monitoramento: {e}", "Sistema")
                    time.sleep(3600)  # Aguardar 1 hora antes de tentar novamente
                    
        except KeyboardInterrupt:
            logger.info("üõë Monitoramento cont√≠nuo interrompido pelo usu√°rio")
            self.telegram.send_notification("üõë MONITORAMENTO CONT√çNUO INTERROMPIDO")
        except Exception as e:
            logger.error(f"‚ùå Erro fatal no monitoramento: {e}")
            self.telegram.send_error_notification(f"Erro fatal no monitoramento: {e}", "Sistema")

def main():
    """Fun√ß√£o principal"""
    # Token do Telegram
    telegram_token = "8450381764:AAHS7rOLqUZjdoMgypzKaots282jf9CQlfw"
    
    # Criar scraper
    scraper = FutbinMassScraper(telegram_token)
    
    # Executar scraping em massa
    scraper.run_mass_scraping()

if __name__ == "__main__":
    main() 